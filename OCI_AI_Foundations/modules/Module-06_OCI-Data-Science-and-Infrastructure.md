# ğŸ“˜ Module 06 â€“ OCI Data Science (ML Services) & AI Infrastructure

---

## 1ï¸âƒ£ Trainerâ€™s Lesson Notes

**OCI Data Science (ML Services layer):**  
Managed platform to **build, train, deploy, and manage** ML models with Python & open source.

**Core principles:**
- **Accelerated** â€“ ready JupyterLab, Conda envs, compute shapes (CPU/GPU).  
- **Collaborative** â€“ Projects, shared assets, reproducibility, auditability.  
- **Enterprise-grade** â€“ IAM, managed infra, patching, security.

**Key features/terms:**
- **Projects** â€“ team workspaces for notebooks/models/jobs.  
- **Notebook Sessions** â€“ managed JupyterLab with selectable shapes & storage.  
- **Conda Environments** â€“ curated envs; easy install/switch.  
- **ADS SDK** â€“ Accelerated Data Science library (AutoML, explainability, model ops, Object Storage integration).  
- **Model Catalog** â€“ store/track/share models with provenance (Git, scripts/notebooks).  
- **Model Deployments** â€“ managed HTTPS endpoints for realtime inference.  
- **Jobs & Pipelines** â€“ repeatable ML tasks & orchestrations.

**GPU Foundations (why GPUs?):**  
Massively parallel math for training/inference; deep learning libs (TF/PyTorch/ONNX) exploit **Tensor Cores**.

**NVIDIA GPU evolution (high level):**
- **A100 (Ampere, 2020)** â†’ DL acceleration with tensor cores.  
- **H100/H200 (Hopper, 2022/2024)** â†’ Transformer Engine; H200 adds more memory.  
- **B200 / GB200 (Blackwell, 2025)** â†’ next-gen scale for frontier LLMs.  
- **Grace CPU & GB200 superchip** â†’ tight CPUâ€“GPU coupling for AI/HPC.

**OCI AI Infrastructure & Scale:**
- Broad GPU shapes (L40, H100/H200, B200, GB200) & **RDMA Superclusters**.  
- Superclusters deliver **lossless, low-latency (â‰ˆ6.5â€“20Âµs)** Clo-fabric with **RoCE** and **placement/locality hints** to minimize cross-block hops and collisions.

**LLM Quick Actions (OCI Data Science):**
- **Deploy** popular base models to GPU VMs/bare metal.  
- **Fine-tune** and **serve** via managed endpoints (supports vLLM/text-embedding containers).

---

## 2ï¸âƒ£ Extra Clarity (Simple Analogies)

- **Projects** = team â€œfoldersâ€ with notebooks/models.  
- **Model Catalog** = GitHub for trained models (versioned artifacts + metadata).  
- **RDMA Supercluster** = high-speed GPU â€œcity gridâ€ where any GPU talks to any other with minimal traffic jams.

---

## 3ï¸âƒ£ DevOps Angle (MLOps)

- Reproducible pipelines with **Jobs/Pipelines**; store artifacts in **Model Catalog**.  
- **ADS SDK** to standardize trainâ†’verifyâ†’saveâ†’deploy steps.  
- Infra as Code for **shape selection**; autoscaling endpoints; logs/metrics wired to Observability.  
- Promotion gates: **dev â†’ staging â†’ prod** with drift checks & canaries.

---

## 4ï¸âƒ£ Exam Focus

- Data Science components (Projects, Notebook Sessions, Conda, ADS, Model Catalog, Deployments, Jobs).  
- What ADS `.prepare() / .verify() / .save() / .deploy()` do.  
- GPU value props; Transformer acceleration; managed infra benefits.  
- Quick Actions for LLMs (deploy/fine-tune/serve).  
- RDMA Supercluster goals: **lossless fabric, QoS buffers, placement/locality hints**.

---

## 5ï¸âƒ£ Beyond Certification

- Integrate with **Object Storage**, **Functions**, **Events**, **API Gateway**.  
- Model governance: lineage, approvals, automated evals (accuracy, latency, cost).  
- Canary & blue/green for model endpoints; shadow testing.

---

## 6ï¸âƒ£ Resume Booster

> â€œProductionized a RandomForest model on **OCI Data Science**: standardized with **ADS** (prepareâ†’verifyâ†’saveâ†’deploy), registered to **Model Catalog**, and exposed a managed HTTPS endpoint with autoscaling.â€

**Mini-project idea:**  
Notebook â†’ ADS workflow â†’ Model Catalog â†’ Deploy â†’ API Gateway front â†’ CloudEvents notify on new versions.

---

## 7ï¸âƒ£ Fast-Track Notes

- Data Science = managed **build/train/deploy** with Jupyter + ADS.  
- Model Catalog centralizes artifacts & provenance.  
- GPUs (H100/H200/B200/GB200) for DL/LLMs; Quick Actions simplify LLM ops.  
- RDMA Superclusters = **low-latency, lossless** scale with placement hints.

---

## ğŸ“¸ Screenshots (Mini-Tests & Practice)

| Test / Demo                | Screenshot    | Notes                                      |
|----------------------------|---------------|--------------------------------------------|
| Test                       | mini-test-05  | Status table showing steps & actions       |
| Questions                  | questions     | âœ… Passed with 100%                        |


---

## ğŸ§ª Appendix â€“ The Demo You Described (Iris RF via ADS)

**Flow:** import libs â†’ load iris â†’ split â†’ train `RandomForestClassifier` â†’ `ads.Model().prepare().verify().save()` â†’ (optionally) `deploy()` and `predict()`.

**Why it matters:** shows the **standard ADS lifecycle** and how **Model Catalog** + **Deployments** make MLOps reproducible.
